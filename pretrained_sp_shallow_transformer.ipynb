{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4OwyEH3Qqb6"
      },
      "source": [
        "Install required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNUNUaDwMYjQ",
        "outputId": "e328e876-7fce-4081-bbd5-951f6c4b6cf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.9/42.9 kB\u001b[0m \u001b[31m700.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m729.2/729.2 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece -q\n",
        "!pip install demoji -q\n",
        "!pip install torchmetrics[text] -q\n",
        "!pip install transformers>=4.0 -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9J5mYCZQuzJ"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "942sDYkfKr4x",
        "outputId": "2d9d5a4d-289c-4da4-d9a3-9ff14f45fa54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BfOLAea2MaJC"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator, vocab\n",
        "from collections import Counter, OrderedDict\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch import Tensor\n",
        "import torch.nn as nn\n",
        "from torch.nn import Transformer\n",
        "from torch.hub import load_state_dict_from_url\n",
        "import math\n",
        "from typing import Iterable, List\n",
        "from timeit import default_timer as timer\n",
        "import torchtext.transforms as T\n",
        "from torch.hub import load_state_dict_from_url\n",
        "import torchtext.data.functional as TDF\n",
        "import sentencepiece as sp\n",
        "from gensim.models import Word2Vec\n",
        "import re\n",
        "import demoji"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rtg6wHVQwCD"
      },
      "source": [
        "Data loading and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PA9GlXCyMkK0"
      },
      "outputs": [],
      "source": [
        "#load samsum dataset\n",
        "def load_dataset(dataset, split):\n",
        "  with open(\"drive/MyDrive/\"+dataset+\"/\"+split+\".json\", \"r\") as f:\n",
        "    data = json.load(f)\n",
        "    return data\n",
        "\n",
        "#preprocess to remove trailing carriage-return and newline\n",
        "def preprocess(dataset):\n",
        "  processed = []\n",
        "  for x in dataset:\n",
        "    processed.append({'summary' : re.sub(\"<[a-z]+_[a-z]+>\",\"\",demoji.replace(x['summary'].replace(\"\\r\",\"\").replace(\"\\n\",\" \"), '')), 'dialogue' : re.sub(\"<[a-z]+_[a-z]+>\",\"\",demoji.replace(x['dialogue'].replace(\"\\r\",\"\").replace(\"\\n\",\" \"), ''))})\n",
        "  return processed\n",
        "\n",
        "train = preprocess(load_dataset(\"corpus\",\"train\"))\n",
        "val = preprocess(load_dataset(\"corpus\",\"val\"))\n",
        "test = preprocess(load_dataset(\"corpus\",\"test\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWjJHvwdRJgb"
      },
      "source": [
        "Build vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mqqQ4EbaQoSV"
      },
      "outputs": [],
      "source": [
        "def make_vocab(fname):\n",
        "  with open(fname, 'r') as f:\n",
        "    lines=f.readlines()\n",
        "  lines=[x.strip(\"\\n\").split(\"\\t\") for x in lines]\n",
        "  tok2ids={}\n",
        "  for i,x in enumerate(lines):\n",
        "    tok2ids[x[0]]=i\n",
        "  voc = vocab(OrderedDict(tok2ids), specials=['<unk>'])\n",
        "  voc.set_default_index(voc['<unk>'])\n",
        "  return voc\n",
        "voc = make_vocab('drive/MyDrive/sum_sp.vocab')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGWlch-vRUgH"
      },
      "source": [
        "Apply text transforms - tokenization, max len padding, bos & eos tokens affixed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9K77OwJdRRdE",
        "outputId": "a5bc7ff6-dd19-4a64-f476-5dcdec13d509"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "padding_idx = 3\n",
        "bos_idx = 1\n",
        "eos_idx = 2\n",
        "src_max_seq_len = 256\n",
        "tgt_max_seq_len = 64\n",
        "\n",
        "src_text_transform = T.Sequential(\n",
        "    T.SentencePieceTokenizer('drive/MyDrive/sum_sp.model'),\n",
        "    T.VocabTransform(voc),\n",
        "    T.Truncate(src_max_seq_len - 2),\n",
        "    T.AddToken(token=bos_idx, begin=True),\n",
        "    T.AddToken(token=eos_idx, begin=False),\n",
        "    T.ToTensor(padding_value=padding_idx),\n",
        "    T.PadTransform(max_length=src_max_seq_len, pad_value=padding_idx),\n",
        ")\n",
        "\n",
        "tgt_text_transform = T.Sequential(\n",
        "    T.SentencePieceTokenizer('drive/MyDrive/sum_sp.model'),\n",
        "    T.VocabTransform(voc),\n",
        "    T.Truncate(tgt_max_seq_len - 2),\n",
        "    T.AddToken(token=bos_idx, begin=True),\n",
        "    T.AddToken(token=eos_idx, begin=False),\n",
        "    T.ToTensor(padding_value=padding_idx),\n",
        "    T.PadTransform(max_length=tgt_max_seq_len, pad_value=padding_idx),\n",
        ")\n",
        "\n",
        "text_transform = T.Sequential(\n",
        "    T.SentencePieceTokenizer('drive/MyDrive/sum_sp.model'),\n",
        "    T.VocabTransform(voc),\n",
        "    T.Truncate(src_max_seq_len - 2),\n",
        "    T.AddToken(token=bos_idx, begin=True),\n",
        "    T.AddToken(token=eos_idx, begin=False),\n",
        ")\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "DEVICE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load pre-trained embeddings and the tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nk6NZpf6S7pn"
      },
      "outputs": [],
      "source": [
        "def load_models(dir):\n",
        "  spp = sp.SentencePieceProcessor()\n",
        "  spp.load(dir+\"sum_sp.model\")\n",
        "  embeddings = np.load(dir+\"sp_emb.npy\")\n",
        "  return spp, embeddings\n",
        "\n",
        "spp, embeddings = load_models(\"drive/MyDrive/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define the transformer network with  a positional embedding and token embedding layer and a linear generator to generate sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5FrJCVh59-GM"
      },
      "outputs": [],
      "source": [
        "# helper Module that adds positional encoding to the token embedding to introduce a notion of word order.\n",
        "#\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self,\n",
        "                 emb_size: int,\n",
        "                 dropout: float,\n",
        "                 maxlen: int =256):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size) # denominator.\n",
        "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
        "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
        "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
        "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
        "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('pos_embedding', pos_embedding)\n",
        "\n",
        "    def forward(self, token_embedding: Tensor):\n",
        "        # print(token_embedding)\n",
        "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
        "\n",
        "# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\n",
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size: int, emb_size):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
        "        self.emb_size = emb_size\n",
        "\n",
        "    def forward(self, tokens: Tensor):\n",
        "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
        "\n",
        "# Seq2Seq Network\n",
        "class Seq2SeqTransformer(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_encoder_layers: int,\n",
        "                 num_decoder_layers: int,\n",
        "                 emb_size: int,\n",
        "                 nhead: int,\n",
        "                 vocab_size: int,\n",
        "                 dim_feedforward: int = 512,\n",
        "                 dropout: float = 0.1):\n",
        "        super(Seq2SeqTransformer, self).__init__()\n",
        "        layer_norm = nn.LayerNorm(emb_size)\n",
        "        encoder_layers = nn.TransformerEncoderLayer(emb_size, nhead, dim_feedforward, dropout)\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layers, num_encoder_layers, layer_norm)\n",
        "        decoder_layers = nn.TransformerDecoderLayer(emb_size, nhead, dim_feedforward, dropout)\n",
        "        self.decoder = nn.TransformerDecoder(decoder_layers, num_decoder_layers, layer_norm)\n",
        "        self.generator = nn.Linear(emb_size, vocab_size)\n",
        "        self.tok_emb = TokenEmbedding(vocab_size, emb_size)\n",
        "        self.positional_encoding = PositionalEncoding(\n",
        "            emb_size, dropout=dropout)\n",
        "\n",
        "    def forward(self,\n",
        "                src: Tensor,\n",
        "                trg: Tensor,\n",
        "                src_mask: Tensor,\n",
        "                tgt_mask: Tensor,\n",
        "                src_padding_mask: Tensor,\n",
        "                tgt_padding_mask: Tensor,\n",
        "                memory_key_padding_mask: Tensor):\n",
        "        src_emb = self.positional_encoding(self.tok_emb(src))\n",
        "        tgt_emb = self.positional_encoding(self.tok_emb(trg))\n",
        "        enc_out = self.encoder(src_emb, src_mask, src_padding_mask)\n",
        "        dec_out = self.decoder(tgt_emb, enc_out, tgt_mask, None, tgt_padding_mask, memory_key_padding_mask)\n",
        "        return self.generator(dec_out)\n",
        "\n",
        "    def encode(self, src: Tensor, src_mask: Tensor):\n",
        "        return self.encoder(self.positional_encoding(\n",
        "                            self.tok_emb(src)), src_mask)\n",
        "\n",
        "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
        "        return self.decoder(self.positional_encoding(\n",
        "                          self.tok_emb(tgt)), memory,\n",
        "                          tgt_mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Utility functions to generate masks for pad tokens and masks for self attention in the decoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "RwigoyEgxBD0"
      },
      "outputs": [],
      "source": [
        "# function to create the target mask, to avoid peeking at subsequent tokens in the decoder self-attention stage.\n",
        "# sz is the maximum length sequence in the batch.\n",
        "# future token indices are filled with -inf and past token indices with 0. Binarized through exponentiation.\n",
        "def generate_square_subsequent_mask(sz):\n",
        "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
        "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "    return mask\n",
        "\n",
        "# function returns source mask, target mask, source_padding_mask and target_padding_mask\n",
        "# src - dialogue/text\n",
        "# tgt - summary\n",
        "def create_mask(src, tgt):\n",
        "    src_seq_len = src.shape[0]\n",
        "    tgt_seq_len = tgt.shape[0]\n",
        "\n",
        "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
        "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
        "\n",
        "    src_padding_mask = (src == padding_idx).transpose(0, 1)\n",
        "    tgt_padding_mask = (tgt == padding_idx).transpose(0, 1)\n",
        "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define model parameters, hyperparameters, loss function, optimizer and a collate function for the data collator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "sobltrVOyLG9"
      },
      "outputs": [],
      "source": [
        "# reproducibility seed\n",
        "torch.manual_seed(0)\n",
        "# tokens in vocabulary\n",
        "VOCAB_SIZE = len(text_transform[1].vocab)\n",
        "# token embedding dimension\n",
        "EMB_SIZE = 256\n",
        "# multi-heads in transformer\n",
        "NHEAD = 4\n",
        "# hidden forward network input dims\n",
        "FFN_HID_DIM = 2048\n",
        "# batch size\n",
        "BATCH_SIZE = 32\n",
        "# encoder and decoder layers in transformer\n",
        "NUM_ENCODER_LAYERS = 2\n",
        "NUM_DECODER_LAYERS = 2\n",
        "\n",
        "# seq2seq model init\n",
        "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
        "                                 NHEAD, VOCAB_SIZE, FFN_HID_DIM)\n",
        "\n",
        "# model parameter init\n",
        "for p in transformer.parameters():\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "\n",
        "with torch.no_grad():\n",
        "  transformer.tok_emb.embedding.weight.copy_(torch.from_numpy(np.load(\"drive/MyDrive/sp_emb.npy\")).float())\n",
        "\n",
        "transformer = transformer.to(DEVICE)\n",
        "\n",
        "# loss function\n",
        "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=padding_idx)\n",
        "\n",
        "#optimizer\n",
        "optimizer = torch.optim.Adam(transformer.parameters())\n",
        "\n",
        "# function to collate data samples into batch tensors\n",
        "def collate_fn(batch):\n",
        "    dialogues = [x['dialogue'] for x in batch]\n",
        "    summaries = [x['summary'] for x in batch]\n",
        "    return src_text_transform(dialogues).transpose(0,1), tgt_text_transform(summaries).transpose(0,1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Train and Eval logic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "OtRa_KoI3XmC"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, optimizer):\n",
        "    model.train()\n",
        "    losses = 0\n",
        "    train_dataloader = DataLoader(train, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "\n",
        "    for src, tgt in train_dataloader:\n",
        "        src = src.to(DEVICE)\n",
        "        tgt = tgt.to(DEVICE)\n",
        "        # print(src.shape,tgt.shape)\n",
        "        tgt_input = tgt[:-1, :]\n",
        "        # print(tgt_input.shape)\n",
        "        # break\n",
        "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "        # print(src_mask, tgt_mask, src_padding_mask,tgt_padding_mask)\n",
        "        # break\n",
        "\n",
        "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        tgt_out = tgt[1:, :]\n",
        "        # tgt_out = tgt\n",
        "        # print(logits.shape, tgt_out.shape)\n",
        "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "        # print(logits)\n",
        "        # print(loss)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
        "        optimizer.step()\n",
        "        losses += loss.item()\n",
        "\n",
        "    return losses / len(list(train_dataloader))\n",
        "\n",
        "\n",
        "def evaluate(model):\n",
        "    model.eval()\n",
        "    losses = 0\n",
        "    val_dataloader = DataLoader(val, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "\n",
        "    for src, tgt in val_dataloader:\n",
        "        src = src.to(DEVICE)\n",
        "        tgt = tgt.to(DEVICE)\n",
        "\n",
        "        tgt_input = tgt[:-1, :]\n",
        "\n",
        "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "\n",
        "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
        "\n",
        "        tgt_out = tgt[1:, :]\n",
        "        # tgt_out = tgt\n",
        "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "        losses += loss.item()\n",
        "\n",
        "    return losses / len(list(val_dataloader))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Utility functions for inference. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "16i4fNRA3uYV"
      },
      "outputs": [],
      "source": [
        "# function to generate output sequence using greedy algorithm\n",
        "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
        "    src = src.to(DEVICE)\n",
        "    src_mask = src_mask.to(DEVICE)\n",
        "\n",
        "    memory = model.encode(src, src_mask)\n",
        "    # print(memory.shape)\n",
        "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
        "    for i in range(max_len-1):\n",
        "        # print(ys.shape)\n",
        "        memory = memory.to(DEVICE)\n",
        "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
        "                    .type(torch.bool)).to(DEVICE)\n",
        "        # print(ys.shape, memory.shape, tgt_mask.shape)\n",
        "        out = model.decode(ys, memory, tgt_mask)\n",
        "        out = out.transpose(0, 1)\n",
        "        prob = model.generator(out[:, -1])\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "        next_word = next_word.item()\n",
        "\n",
        "        ys = torch.cat([ys,\n",
        "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
        "        if next_word == eos_idx:\n",
        "            break\n",
        "        # print(prob.shape)\n",
        "    return ys\n",
        "\n",
        "# actual function to translate input sentence into target language\n",
        "def translate(model: torch.nn.Module, src_sentence: str):\n",
        "    model.eval()\n",
        "    src = src_text_transform(src_sentence).view(-1, 1)\n",
        "    num_tokens = src.shape[0]\n",
        "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
        "    # print(src_mask)\n",
        "    tgt_tokens = greedy_decode(\n",
        "        model,  src, src_mask, max_len=num_tokens, start_symbol=bos_idx).flatten()\n",
        "    # print(tgt_tokens)\n",
        "    return spp.decode(tgt_tokens.cpu().tolist())\n",
        "    # return \" \".join(text_transform[1].vocab.lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BeamSearchDecoder(nn.Module):\n",
        "    def __init__(self, transformer_model, tgt_vocab_size, max_len, beam_width=5, topk=3):\n",
        "        super(BeamSearchDecoder, self).__init__()\n",
        "        self.transformer_model = transformer_model\n",
        "        self.tgt_vocab_size = tgt_vocab_size\n",
        "        self.max_len = max_len\n",
        "        self.beam_width = beam_width\n",
        "        self.topk = topk\n",
        "\n",
        "    def forward(self, src, tgt_start_token):\n",
        "        self.transformer_model.eval()\n",
        "        batch_size = src.shape[1]\n",
        "        batch = [[{'sequence': [tgt_start_token], 'score': 0.0}] for _ in range(batch_size)]\n",
        "\n",
        "        for t in range(1, self.max_len):\n",
        "\n",
        "            current_tokens = torch.tensor([b['sequence'][-1] for beam in batch for b in beam], dtype=torch.long).unsqueeze(0)\n",
        "            current_tokens = current_tokens.to(DEVICE)\n",
        "\n",
        "            repeat = int(current_tokens.shape[-1]/batch_size)\n",
        "\n",
        "            rep_src = src.unsqueeze(1).repeat(1,repeat,1).view(256,-1)\n",
        "\n",
        "            src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(rep_src, current_tokens)\n",
        "\n",
        "            with torch.no_grad():\n",
        "              output = self.transformer_model(rep_src, current_tokens, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
        "\n",
        "            last_token_pred = output[-1, :, :]\n",
        "\n",
        "            width_beam = []\n",
        "            for batch_idx, beams in enumerate(batch):\n",
        "              new_beam = []\n",
        "              for b in beams:\n",
        "                  sequence = b['sequence']\n",
        "                  score = b['score']\n",
        "\n",
        "                  top_k_scores, top_k_tokens = torch.topk(last_token_pred[batch_idx], self.topk)\n",
        "\n",
        "                  for i in range(self.topk):\n",
        "                      next_token = top_k_tokens[i].item()\n",
        "                      next_score = score + top_k_scores[i].item()\n",
        "\n",
        "                      new_sequence = sequence + [next_token]\n",
        "                      new_beam.append({'sequence': new_sequence, 'score': next_score})\n",
        "\n",
        "              sorted_beam = sorted(new_beam, key=lambda x: x['score'], reverse=True)\n",
        "              width_beam.append(sorted_beam[:self.beam_width])\n",
        "            batch = width_beam\n",
        "\n",
        "        check_for_eos = [b['sequence'] for beam in batch for b in beam]\n",
        "        for i, tok in enumerate(check_for_eos):\n",
        "          if tok[-1] == eos_idx:\n",
        "            return check_for_eos[i]\n",
        "\n",
        "        output = list(map(lambda y: sorted(y, key=lambda x: x['score'], reverse=True)[0]['sequence'], batch))\n",
        "\n",
        "        return output\n",
        "\n",
        "def beam_translate(model: torch.nn.Module, src_tokens: List, max_len):\n",
        "    model.eval()\n",
        "    # src_tokens = src_tokens.to(DEVICE)\n",
        "    beam_decoder = BeamSearchDecoder(model, len(voc), max_len)\n",
        "    tgt_tokens = beam_decoder(src_tokens, bos_idx)\n",
        "    return spp.decode(tgt_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZzjhabS30b2",
        "outputId": "6a027f08-2514-440c-c82e-908b2c1dc9d9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_jit_internal.py:1297: UserWarning: The inner type of a container is lost when calling torch.jit.isinstance in eager mode. For example, List[int] would become list and therefore falsely return True for List[float] or List[str].\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1, Train loss: 5.580, Val loss: 5.032, Epoch time = 62.473s\n",
            "Epoch: 2, Train loss: 4.658, Val loss: 4.918, Epoch time = 60.336s\n",
            "Epoch: 3, Train loss: 4.308, Val loss: 4.906, Epoch time = 63.040s\n",
            "Epoch: 4, Train loss: 4.023, Val loss: 4.991, Epoch time = 61.690s\n",
            "{'summary': \"Ali left his wallet at Mohammad's place. Mohammad'll bring it to uni tomorrow.\", 'dialogue': \"Ali: I think I left my wallet at your place yesterday. Could you check?  Mohammad: Give me a sec, I'll have a look around my room. Ali: OK. Mohammad: Found it! Ali: Phew, I don't know what I'd do if it wasn't there. Can you bring it to uni tomorrow? Mohammad: Sure thing.\"}\n",
            "The team is in the office is in the office.\n",
            "Epoch: 5, Train loss: 3.774, Val loss: 5.112, Epoch time = 63.612s\n",
            "Epoch: 6, Train loss: 3.559, Val loss: 5.245, Epoch time = 62.120s\n",
            "Epoch: 7, Train loss: 3.368, Val loss: 5.299, Epoch time = 63.877s\n",
            "Epoch: 8, Train loss: 3.189, Val loss: 5.391, Epoch time = 62.616s\n",
            "Epoch: 9, Train loss: 3.023, Val loss: 5.564, Epoch time = 61.683s\n",
            "{'summary': \"Ali left his wallet at Mohammad's place. Mohammad'll bring it to uni tomorrow.\", 'dialogue': \"Ali: I think I left my wallet at your place yesterday. Could you check?  Mohammad: Give me a sec, I'll have a look around my room. Ali: OK. Mohammad: Found it! Ali: Phew, I don't know what I'd do if it wasn't there. Can you bring it to uni tomorrow? Mohammad: Sure thing.\"}\n",
            "Tom is going to buy a new dress for Christmas.\n",
            "Epoch: 10, Train loss: 2.867, Val loss: 5.670, Epoch time = 61.741s\n"
          ]
        }
      ],
      "source": [
        "NUM_EPOCHS = 10\n",
        "min_loss = 1000\n",
        "for epoch in range(1, NUM_EPOCHS+1):\n",
        "    start_time = timer()\n",
        "    train_loss = train_epoch(transformer, optimizer)\n",
        "    end_time = timer()\n",
        "    val_loss = evaluate(transformer)\n",
        "    if not epoch % 5:\n",
        "      print(test[70])\n",
        "      print(translate(transformer, test[70]['dialogue']))\n",
        "    if val_loss < min_loss:\n",
        "      min_loss = val_loss\n",
        "      torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': transformer.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'train_loss': train_loss,\n",
        "            'val_loss': val_loss\n",
        "            }, 'drive/MyDrive/checkpoints/pretrained_sp_tok_latest.pth')\n",
        "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "MK5oSZ1i0b0x"
      },
      "outputs": [],
      "source": [
        "from torchmetrics.text.rouge import ROUGEScore\n",
        "from torchmetrics.text.bert import BERTScore\n",
        "from torchmetrics.text import BLEUScore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compute metrics on test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmTX0l_Pwy4E",
        "outputId": "973478ee-3331-497c-f4ca-ab207518fad4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:42: UserWarning: The argument `model_name_or_path` was not specified while it is required when the default `transformers` model is used. It will use the default recommended model - 'roberta-large'.\n",
            "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "targets = [x['summary'] for x in test]\n",
        "preds = [translate(transformer, x['dialogue']) for x in test]\n",
        "# print([preds])\n",
        "# print([targets])\n",
        "rouge_score=ROUGEScore()\n",
        "bert_score = BERTScore()\n",
        "bleu_score = BLEUScore()\n",
        "# bleu = bleu_score(preds, targets)\n",
        "rouge = rouge_score(preds,targets)\n",
        "bert = bert_score(preds, targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Display metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ycbc1VPw1Gc",
        "outputId": "c5e2dc8d-c8a1-493b-f1ea-d7cf6251a950"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0046)\n"
          ]
        }
      ],
      "source": [
        "bleu_targets = [[x] for x in targets]\n",
        "bleu = bleu_score(preds, bleu_targets)\n",
        "print(bleu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyAZUqe8w148",
        "outputId": "d9211609-e5ae-4834-c6ff-787b4c7a2fab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'rouge1_fmeasure': tensor(0.1242), 'rouge1_precision': tensor(0.1438), 'rouge1_recall': tensor(0.1212), 'rouge2_fmeasure': tensor(0.0102), 'rouge2_precision': tensor(0.0123), 'rouge2_recall': tensor(0.0097), 'rougeL_fmeasure': tensor(0.1029), 'rougeL_precision': tensor(0.1191), 'rougeL_recall': tensor(0.1009), 'rougeLsum_fmeasure': tensor(0.1162), 'rougeLsum_precision': tensor(0.1346), 'rougeLsum_recall': tensor(0.1135)}\n"
          ]
        }
      ],
      "source": [
        "print(rouge)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODazvgajw4lz",
        "outputId": "cd589709-9ff1-481e-c04d-847ca7ec6dfd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'precision': tensor(0.9767), 'recall': tensor(0.9712), 'f1': tensor(0.9739)}"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bert = {k:v.mean() for k,v in bert.items()}\n",
        "bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2S-Q0oeW0rpr"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
