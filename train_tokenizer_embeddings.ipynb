{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train sentence piece tokenizer and word2vec embeddings on the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as sp\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.SentencePieceTrainer.train(input='drive/MyDrive/sp_data.text', model_prefix='drive/MyDrive/sum_sp', vocab_size=30000, user_defined_symbols=['<pad>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"drive/MyDrive/sp_data.text\", 'r') as f:\n",
    "    lines=f.readlines()\n",
    "lines=[text_transform(x) for x in lines]\n",
    "# lines = list(map(lambda x: x[0], lines))\n",
    "w2v_model = Word2Vec(lines, min_count=1, window=7, workers=4, vector_size=256, sg=1)\n",
    "w2v_model.save(\"drive/MyDrive/sp_word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = w2v_model.vector_size\n",
    "vocab_size = len(spp)\n",
    "table = np.array([w2v_model.wv[w2v_model.wv.key_to_index[i]] if i in w2v_model.wv.key_to_index.keys() else np.zeros([dim]) for i in range(vocab_size)])\n",
    "# np.where(np.sum(table, axis=1)==0)[0].shape\n",
    "np.save(\"drive/MyDrive/sp_emb.npy\", table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train word2vec embeddings on the tokens generated by the spacy english word tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"drive/MyDrive/sp_data.text\", 'r') as f:\n",
    "    lines=f.readlines()\n",
    "lines=[text_transform(tokenizer(x)) for x in lines]\n",
    "# lines = list(map(lambda x: x[0], lines))\n",
    "# print(lines[:2])\n",
    "w2v_model = Word2Vec(lines, min_count=1, window=7, workers=4, vector_size=256, sg=1)\n",
    "w2v_model.save(\"drive/MyDrive/word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = w2v_model.vector_size\n",
    "vocab_size = len(v1)\n",
    "table = np.array([w2v_model.wv[w2v_model.wv.key_to_index[i]] if i in w2v_model.wv.key_to_index.keys() else np.zeros([dim]) for i in range(vocab_size)])\n",
    "# np.where(np.sum(table, axis=1)==0)[0].shape\n",
    "np.save(\"drive/MyDrive/emb.npy\", table)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
